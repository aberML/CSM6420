{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 - SVM with Feature Selection and Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply use Support Vector Machines with parameter tuning using GridSearch SV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/CompTools/miniconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "df['Age'] = df['Age'].fillna(age_mean)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Feature selection\n",
    "Quite often feature selection could improve model performance if the input data contain very noisy/irrelevant variables, or if the variables are highly correlated.\n",
    "\n",
    "See scikit learn documentation for details on usage of various feature selection methods \n",
    "http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "Here we will use the linear SVC based RFE for feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RFE: Recursive Feature Elimination\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "estimator = SVC(kernel=\"linear\")\n",
    "selector = RFE(estimator, 5, step=1)\n",
    "selector = selector.fit(train_data[0:,2:], train_data[0:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Selected features using RFE: ', df.columns.values[selector.support_])\n",
    "print(selector.support_ )\n",
    "print(selector.ranking_ )\n",
    "print(train_data.shape)\n",
    "\n",
    "# Subset of training input with selected features only\n",
    "print(selector.transform(train_data[0:,2:]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Perform feature selection using decision forests. See example: \n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for parameter tuning without feature selection\n",
    "First, without feature selection we build the parameter grid for SVC, noting that the default parameters are C = 1.0, and  gamma = 0.0 or 1/n_features for rbf/poly/sigmoid kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "\n",
    "parameter_grid = [\n",
    "    {'kernel':['linear'], 'C': [1., 10.]},\n",
    "    {'kernel':['rbf'], 'C': [1., 10.], 'gamma': [0.1, 1.]}\n",
    "]\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "grid_search = GridSearchCV(SVC(), parameter_grid, cv=5, verbose=3)\n",
    "grid_search.fit(train_data[0:,2:], train_data[0:,0])\n",
    "\n",
    "# Sorting the score and print out the parameters with the best scores\n",
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "# Controling the random split of the cross-validation and using stratified CV.\n",
    "random_seed = 1234\n",
    "scv = SKFold(y=train_data[0:,0], n_folds=5, random_state=random_seed)\n",
    "\n",
    "# Use .transform method to get the input data with selected features\n",
    "grid_search_FS = GridSearchCV(SVC(), parameter_grid, cv=scv, verbose=3)\n",
    "grid_search_FS.fit(selector.transform(train_data[0:,2:]), train_data[0:,0])\n",
    "\n",
    "# print out the best scoring parameters\n",
    "sorted(grid_search_FS.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "print(grid_search_FS.best_score_)\n",
    "print(grid_search_FS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose (hyper-)parameters and features that gives the best performance on CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', C=10.0, gamma=0.1)\n",
    "model = model.fit(selector.transform(train_data[0:,2:]), train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "\n",
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "df_test.head(5)\n",
    "# Use the same selected features for prediction\n",
    "output = model.predict(selector.transform(test_data[0:,1:]))\n",
    "# It's also possible to output the decision function (the continuous score) before taking the binary output.\n",
    "output1 = model.decision_function(selector.transform(test_data[0:,1:]))\n",
    "# Store the prediction output in a DataFrame\n",
    "df_predict=pd.DataFrame(np.c_[test_data[0:,0], output1, output], columns=['Passengerid', 'Decision_score', 'Prediction'])\n",
    "df_predict.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('results/titanic_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
